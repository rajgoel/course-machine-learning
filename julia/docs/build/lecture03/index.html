<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Lecture 03: Deep Neural Networks · MachineLearningCourse.jl</title><meta name="title" content="Lecture 03: Deep Neural Networks · MachineLearningCourse.jl"/><meta property="og:title" content="Lecture 03: Deep Neural Networks · MachineLearningCourse.jl"/><meta property="twitter:title" content="Lecture 03: Deep Neural Networks · MachineLearningCourse.jl"/><meta name="description" content="Documentation for MachineLearningCourse.jl."/><meta property="og:description" content="Documentation for MachineLearningCourse.jl."/><meta property="twitter:description" content="Documentation for MachineLearningCourse.jl."/><meta property="og:url" content="https://rajgoel.github.io/course-machine-learning/julia/lecture03/"/><meta property="twitter:url" content="https://rajgoel.github.io/course-machine-learning/julia/lecture03/"/><link rel="canonical" href="https://rajgoel.github.io/course-machine-learning/julia/lecture03/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">MachineLearningCourse.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Lecture 03: Deep Neural Networks</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Lecture 03: Deep Neural Networks</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/rajgoel/course-machine-learning" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/rajgoel/course-machine-learning/blob/main/julia/docs/src/lecture03.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Lecture-03:-Deep-Neural-Networks"><a class="docs-heading-anchor" href="#Lecture-03:-Deep-Neural-Networks">Lecture 03: Deep Neural Networks</a><a id="Lecture-03:-Deep-Neural-Networks-1"></a><a class="docs-heading-anchor-permalink" href="#Lecture-03:-Deep-Neural-Networks" title="Permalink"></a></h1><p>This module implements a complete deep neural network from scratch in Julia, including:</p><ul><li>Forward propagation</li><li>Backpropagation</li><li>Gradient descent training</li><li>MNIST digit classification demo</li></ul><h2 id="Architecture"><a class="docs-heading-anchor" href="#Architecture">Architecture</a><a id="Architecture-1"></a><a class="docs-heading-anchor-permalink" href="#Architecture" title="Permalink"></a></h2><p>The implementation uses a flexible architecture where you can specify any number of layers:</p><pre><code class="language-julia hljs"># Example architectures:
network_small = DNN([2, 4, 1])           # Simple: 2 → 4 → 1
network_mnist = DNN([784, 128, 64, 10])  # MNIST: 784 → 128 → 64 → 10
network_deep = DNN([100, 50, 25, 10, 1]) # Deep: 100 → 50 → 25 → 10 → 1</code></pre><h2 id="Key-Features"><a class="docs-heading-anchor" href="#Key-Features">Key Features</a><a id="Key-Features-1"></a><a class="docs-heading-anchor-permalink" href="#Key-Features" title="Permalink"></a></h2><h3 id="Activation-Functions"><a class="docs-heading-anchor" href="#Activation-Functions">Activation Functions</a><a id="Activation-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Activation-Functions" title="Permalink"></a></h3><ul><li><strong>Hidden layers</strong>: ReLU activation (σ(z) = max(0, z))</li><li><strong>Output layer</strong>: Linear activation (for regression/raw scores)</li></ul><h3 id="Loss-Function"><a class="docs-heading-anchor" href="#Loss-Function">Loss Function</a><a id="Loss-Function-1"></a><a class="docs-heading-anchor-permalink" href="#Loss-Function" title="Permalink"></a></h3><ul><li>Mean Squared Error: ℒ = ||y - ŷ||²</li></ul><h3 id="Initialization"><a class="docs-heading-anchor" href="#Initialization">Initialization</a><a id="Initialization-1"></a><a class="docs-heading-anchor-permalink" href="#Initialization" title="Permalink"></a></h3><ul><li><strong>Weights</strong>: He initialization (W ~ N(0, 2/n_in))</li><li><strong>Biases</strong>: Zero initialization</li></ul><h3 id="Training-Algorithm"><a class="docs-heading-anchor" href="#Training-Algorithm">Training Algorithm</a><a id="Training-Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Training-Algorithm" title="Permalink"></a></h3><ul><li>Standard gradient descent</li><li>Configurable learning rate</li><li>Configurable number of epochs</li></ul><h2 id="MNIST-Demo"><a class="docs-heading-anchor" href="#MNIST-Demo">MNIST Demo</a><a id="MNIST-Demo-1"></a><a class="docs-heading-anchor-permalink" href="#MNIST-Demo" title="Permalink"></a></h2><p>The demo showcases the neural network on the classic MNIST handwritten digit classification task:</p><pre><code class="language-julia hljs">demo()  # Run with defaults
demo(0.01, 100)  # Custom learning rate and epochs</code></pre><h3 id="Demo-Process"><a class="docs-heading-anchor" href="#Demo-Process">Demo Process</a><a id="Demo-Process-1"></a><a class="docs-heading-anchor-permalink" href="#Demo-Process" title="Permalink"></a></h3><ol><li><strong>Data Loading</strong>: Downloads and preprocesses MNIST dataset</li><li><strong>Preprocessing</strong>: <ul><li>Flattens 28×28 images to 784-dimensional vectors</li><li>Normalizes pixel values to [0, 1]</li><li>One-hot encodes labels for 10 digit classes</li></ul></li><li><strong>Training</strong>: Trains network using backpropagation</li><li><strong>Evaluation</strong>: <ul><li>Computes overall test accuracy</li><li>Shows per-digit classification performance</li><li>Displays sample predictions with confidence scores</li></ul></li></ol><h3 id="Expected-Performance"><a class="docs-heading-anchor" href="#Expected-Performance">Expected Performance</a><a id="Expected-Performance-1"></a><a class="docs-heading-anchor-permalink" href="#Expected-Performance" title="Permalink"></a></h3><p>With default settings, the network typically achieves:</p><ul><li><strong>Training time</strong>: ~2-3 minutes</li><li><strong>Test accuracy</strong>: ~85-95% (depending on random initialization)</li><li><strong>Per-digit performance</strong>: Usually best on digits 0, 1, 6; more challenging on 4, 8, 9</li></ul><h2 id="Mathematical-Background"><a class="docs-heading-anchor" href="#Mathematical-Background">Mathematical Background</a><a id="Mathematical-Background-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-Background" title="Permalink"></a></h2><h3 id="Forward-Propagation"><a class="docs-heading-anchor" href="#Forward-Propagation">Forward Propagation</a><a id="Forward-Propagation-1"></a><a class="docs-heading-anchor-permalink" href="#Forward-Propagation" title="Permalink"></a></h3><p>For each layer l:</p><pre><code class="nohighlight hljs">z^[l] = W^[l] * a^[l-1] + b^[l]
a^[l] = σ(z^[l])</code></pre><h3 id="Backpropagation"><a class="docs-heading-anchor" href="#Backpropagation">Backpropagation</a><a id="Backpropagation-1"></a><a class="docs-heading-anchor-permalink" href="#Backpropagation" title="Permalink"></a></h3><p>Computing gradients via chain rule:</p><pre><code class="nohighlight hljs">δ^[L] = ∂ℒ/∂a^[L]
δ^[l] = (W^[l+1])^T * δ^[l+1] ⊙ σ&#39;(z^[l])
∂ℒ/∂W^[l] = δ^[l] * (a^[l-1])^T
∂ℒ/∂b^[l] = δ^[l]</code></pre><h3 id="Parameter-Updates"><a class="docs-heading-anchor" href="#Parameter-Updates">Parameter Updates</a><a id="Parameter-Updates-1"></a><a class="docs-heading-anchor-permalink" href="#Parameter-Updates" title="Permalink"></a></h3><p>Standard gradient descent:</p><pre><code class="nohighlight hljs">W^[l] ← W^[l] - α * ∂ℒ/∂W^[l]
b^[l] ← b^[l] - α * ∂ℒ/∂b^[l]</code></pre></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Saturday 23 August 2025 14:56">Saturday 23 August 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
